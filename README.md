# Deep Learning from First Principles ğŸ§ 

> "What I cannot create, I do not understand." â€” Richard Feynman

## ğŸš€ About The Project
This repository documents my journey building a Neural Network framework from scratch using **only NumPy**. No PyTorch, no TensorFlow, no magic black boxes.

## ğŸ› ï¸ Tech Stack
* **Python 3.10+**
* **NumPy** (Linear Algebra)

## ğŸ“‚ Progress Log
| Day | Concept | Status |
| :--- | :--- | :--- |
| **01** | Dense Layer (Forward Pass) | âœ… Completed |
| **02** | Activation Functions (ReLU) | â³ Upcoming |
| **03** | Backpropagation | â³ Upcoming |

## ğŸ’¡ Key Learnings (Day 1)
* **Initialization matters:** `0.1 * randn` prevents gradient explosion.
* **Vectorization:** Using `np.dot` is infinitely faster than Python loops.
* **Shapes:** Debugging matrix dimensions `(N, D)` vs `(D, K)` is 90% of the work.

## ğŸ’» How to Run
```bash
# Clone the repo
git clone [https://github.com/Bhanu-teja-VCE/numpy-neural-network.git](https://github.com/Bhanu-teja-VCE/numpy-neural-network.git)

# Install dependencies
pip install numpy

# Run the Day 1 script
python main.py
```
